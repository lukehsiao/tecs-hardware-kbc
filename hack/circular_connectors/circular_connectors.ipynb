{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Configure logging for Fonduer\n",
    "logging.basicConfig(stream=sys.stdout, format='[%(levelname)s] %(name)s:%(lineno)s - %(message)s')\n",
    "logger = logging.getLogger('fonduer')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "PARALLEL = 16 # assuming a quad-core machine\n",
    "ATTRIBUTE = \"circular_connectors\"\n",
    "conn_string = 'postgresql://localhost:5432/' + ATTRIBUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you've run this before, set FIRST_TIME to False to save time\n",
    "FIRST_TIME = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.meta:86 - Connecting user:None to localhost:5432/circular_connectors\n",
      "[INFO] fonduer.meta:110 - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "from fonduer import Meta\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer:8 - # of train Documents: 100\n",
      "[INFO] fonduer:9 - # of dev Documents: 100\n",
      "[INFO] fonduer:10 - # of test Documents: 98\n"
     ]
    }
   ],
   "source": [
    "from hack.utils import parse_dataset\n",
    "\n",
    "dirname = \".\"\n",
    "\n",
    "docs, train_docs, dev_docs, test_docs = parse_dataset(\n",
    "    session, dirname, first_time=FIRST_TIME, parallel=PARALLEL, max_docs=100\n",
    ")\n",
    "logger.info(f\"# of train Documents: {len(train_docs)}\")\n",
    "logger.info(f\"# of dev Documents: {len(dev_docs)}\")\n",
    "logger.info(f\"# of test Documents: {len(test_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer:3 - Documents: 298\n",
      "[INFO] fonduer:4 - Sections: 298\n",
      "[INFO] fonduer:5 - Paragraphs: 330839\n",
      "[INFO] fonduer:6 - Sentences: 341046\n",
      "[INFO] fonduer:7 - Figures: 21269\n"
     ]
    }
   ],
   "source": [
    "from fonduer.parser.models import Document, Section, Paragraph, Sentence, Figure\n",
    "\n",
    "logger.info(f\"Documents: {session.query(Document).count()}\")\n",
    "logger.info(f\"Sections: {session.query(Section).count()}\")\n",
    "logger.info(f\"Paragraphs: {session.query(Paragraph).count()}\")\n",
    "logger.info(f\"Sentences: {session.query(Sentence).count()}\")\n",
    "logger.info(f\"Figures: {session.query(Figure).count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import mention_subclass\n",
    "\n",
    "Thumbnails = mention_subclass(\"Thumbnails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates import MentionFigures\n",
    "\n",
    "thumbnails_img = MentionFigures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.matchers import _Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class HasFigures(_Matcher):   \n",
    "    def _f(self, m):\n",
    "        file_path = \"\"\n",
    "        for prefix in [\"data/train/html/\", \"data/dev/html/\", \"data/test/html/\"]:\n",
    "            if os.path.exists(prefix + m.figure.url):\n",
    "                file_path = prefix + m.figure.url\n",
    "        if file_path == \"\":\n",
    "            return False\n",
    "        img = Image.open(file_path)\n",
    "        width, height = img.size\n",
    "        min_value = min(width, height)\n",
    "        return min_value > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer:13 - Total Mentions: 8917\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates import MentionExtractor\n",
    "from fonduer.candidates.matchers import DoNothingMatcher\n",
    "\n",
    "mention_extractor = MentionExtractor(\n",
    "    session, [Thumbnails], [thumbnails_img], [HasFigures()], parallelism=PARALLEL\n",
    ")\n",
    "\n",
    "from fonduer.candidates.models import Mention\n",
    "\n",
    "if FIRST_TIME:\n",
    "    mention_extractor.apply(docs)\n",
    "\n",
    "logger.info(\"Total Mentions: {}\".format(session.query(Mention).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import candidate_subclass\n",
    "\n",
    "ThumbnailLabel = candidate_subclass(\"ThumbnailLabel\", [Thumbnails])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer.candidates.candidates:125 - Clearing table thumbnail_label (split 0)\n",
      "[INFO] fonduer.utils.udf:57 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10efdc08ff704cce81525d7c21588ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] fonduer.candidates.candidates:125 - Clearing table thumbnail_label (split 1)\n",
      "[INFO] fonduer.utils.udf:57 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cca416157da4d4185b1d770379f0ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] fonduer.candidates.candidates:125 - Clearing table thumbnail_label (split 2)\n",
      "[INFO] fonduer.utils.udf:57 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d78fe5a01ef4cada8b38868d66ba0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates import CandidateExtractor\n",
    "\n",
    "candidate_extractor = CandidateExtractor(\n",
    "    session, [ThumbnailLabel], throttlers=[None], parallelism=PARALLEL\n",
    ")\n",
    "\n",
    "if FIRST_TIME or True:\n",
    "    candidate_extractor.apply(train_docs, split=0)\n",
    "    candidate_extractor.apply(dev_docs, split=1)\n",
    "    candidate_extractor.apply(test_docs, split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cands = candidate_extractor.get_candidates(split=0)\n",
    "dev_cands = candidate_extractor.get_candidates(split=1)\n",
    "test_cands = candidate_extractor.get_candidates(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fonduer:1 - Total train candidate:\t7256\n",
      "[INFO] fonduer:2 - Total dev candidate:\t453\n",
      "[INFO] fonduer:3 - Total test candidate:\t1208\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Total train candidate:\\t{}\".format(len(train_cands[0])))\n",
    "logger.info(\"Total dev candidate:\\t{}\".format(len(dev_cands[0])))\n",
    "logger.info(\"Total test candidate:\\t{}\".format(len(test_cands[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open(\"data/ground_truth.txt\", \"r\")\n",
    "gt = set()\n",
    "for line in fin:\n",
    "    gt.add(\"::\".join(line.lower().split()))\n",
    "fin.close()\n",
    "# gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE=1\n",
    "FALSE=2\n",
    "ABSTAIN=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_gt_label(c):\n",
    "    doc_file_id = f\"{c[0].context.figure.document.name.lower()}.pdf::{os.path.basename(c[0].context.figure.url.lower())}\"\n",
    "#     print(doc_file_id)\n",
    "    return TRUE if doc_file_id in gt else FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = {0:0, 1:0, 2:0}\n",
    "\n",
    "gt_dev_pb = []\n",
    "gt_dev = []\n",
    "gt_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cand in dev_cands[0]:\n",
    "    if LF_gt_label(cand) == 1:\n",
    "        ans[1] += 1\n",
    "        gt_dev_pb.append([1., 0.])\n",
    "        gt_dev.append(1.)\n",
    "    else:\n",
    "        ans[2] += 1\n",
    "        gt_dev_pb.append([0., 1.])\n",
    "        gt_dev.append(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 69, 2: 384}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = {0:0, 1:0, 2:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cand in test_cands[0]:\n",
    "    gt_test.append(LF_gt_label(cand))\n",
    "    ans[gt_test[-1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 160, 2: 1048}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disc_model.torchnet import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     ImageList(\n",
    "#         data=all_cands,\n",
    "#         label=torch.Tensor(all_label),\n",
    "# #         label=torch.Tensor(gt_dev_pb),\n",
    "#         transform=transform(input_size),\n",
    "#         prefix=\"data/dev/html/\",\n",
    "#     ),\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle = True,\n",
    "# #     sampler = sampler\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ImageList(\n",
    "        data=dev_cands[0],\n",
    "#         label=torch.Tensor(gt_dev),\n",
    "        label=torch.Tensor(gt_dev_pb),\n",
    "        transform=transform(input_size),\n",
    "        prefix=\"data/dev/html/\",\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "#     sampler = sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loader = torch.utils.data.DataLoader(\n",
    "    ImageList(\n",
    "        data=dev_cands[0],\n",
    "#         label=torch.Tensor(gt_dev),\n",
    "        label=gt_dev,\n",
    "        transform=transform(input_size),\n",
    "        prefix=\"data/dev/html/\",\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    ImageList(\n",
    "        data=test_cands[0],\n",
    "        label=gt_test,\n",
    "        transform=transform(input_size),\n",
    "        prefix=\"data/test/html/\",\n",
    "    ),\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal import EndModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_config = {\n",
    "    # GENERAL\n",
    "    \"seed\": None,\n",
    "    \"verbose\": True,\n",
    "    \"show_plots\": True,\n",
    "    # Network\n",
    "    # The first value is the output dim of the input module (or the sum of\n",
    "    # the output dims of all the input modules if multitask=True and\n",
    "    # multiple input modules are provided). The last value is the\n",
    "    # output dim of the head layer (i.e., the cardinality of the\n",
    "    # classification task). The remaining values are the output dims of\n",
    "    # middle layers (if any). The number of middle layers will be inferred\n",
    "    # from this list.\n",
    "    #     \"layer_out_dims\": [10, 2],\n",
    "    # Input layer configs\n",
    "    \"input_layer_config\": {\n",
    "        \"input_relu\": False,\n",
    "        \"input_batchnorm\": False,\n",
    "        \"input_dropout\": 0.0,\n",
    "    },\n",
    "    # Middle layer configs\n",
    "    \"middle_layer_config\": {\n",
    "        \"middle_relu\": False,\n",
    "        \"middle_batchnorm\": False,\n",
    "        \"middle_dropout\": 0.0,\n",
    "    },\n",
    "    # Can optionally skip the head layer completely, for e.g. running baseline\n",
    "    # models...\n",
    "    \"skip_head\": True,\n",
    "    # GPU\n",
    "    \"use_cuda\": True,\n",
    "    # MODEL CLASS\n",
    "    \"resnet18\"\n",
    "    # DATA CONFIG\n",
    "    \"src\": \"gm\",\n",
    "    # TRAINING\n",
    "    \"train_config\": {\n",
    "        # Display\n",
    "        \"print_every\": 1,  # Print after this many epochs\n",
    "        \"disable_prog_bar\": False,  # Disable progress bar each epoch\n",
    "        # Dataloader\n",
    "        \"data_loader_config\": {\"batch_size\": 32, \"num_workers\": 8, \"sampler\": None},\n",
    "        # Loss weights\n",
    "        \"loss_weights\": [0.5, 0.5],\n",
    "        # Train Loop\n",
    "        \"n_epochs\": 20,\n",
    "        # 'grad_clip': 0.0,\n",
    "        \"l2\": 0.0,\n",
    "        # \"lr\": 0.01,\n",
    "        \"validation_metric\": \"accuracy\",\n",
    "        \"validation_freq\": 1,\n",
    "        # Evaluate dev for during training every this many epochs\n",
    "        # Optimizer\n",
    "        \"optimizer_config\": {\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"optimizer_common\": {\"lr\": 0.01},\n",
    "            # Optimizer - SGD\n",
    "            \"sgd_config\": {\"momentum\": 0.9},\n",
    "            # Optimizer - Adam\n",
    "            \"adam_config\": {\"betas\": (0.9, 0.999)},\n",
    "        },\n",
    "        # Scheduler\n",
    "        \"scheduler_config\": {\n",
    "            \"scheduler\": \"reduce_on_plateau\",\n",
    "            # ['constant', 'exponential', 'reduce_on_plateu']\n",
    "            # Freeze learning rate initially this many epochs\n",
    "            \"lr_freeze\": 0,\n",
    "            # Scheduler - exponential\n",
    "            \"exponential_config\": {\"gamma\": 0.9},  # decay rate\n",
    "            # Scheduler - reduce_on_plateau\n",
    "            \"plateau_config\": {\n",
    "                \"factor\": 0.5,\n",
    "                \"patience\": 1,\n",
    "                \"threshold\": 0.0001,\n",
    "                \"min_lr\": 1e-5,\n",
    "            },\n",
    "        },\n",
    "        # Checkpointer\n",
    "        \"checkpoint\": True,\n",
    "        \"checkpoint_config\": {\n",
    "            \"checkpoint_min\": -1,\n",
    "            # The initial best score to beat to merit checkpointing\n",
    "            \"checkpoint_runway\": 0,\n",
    "            # Don't start taking checkpoints until after this many epochs\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weight vector [0.5, 0.5]...\n",
      "\n",
      "Network architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[0] Testing {'l2': 1e-05, 'lr': 0.06473640870883719}\n",
      "============================================================\n",
      "Using GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s, avg_loss=9.24] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.848\n",
      "[E:0]\tTrain Loss: 0.816\tDev score: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.50it/s, avg_loss=37.7]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:1]\tTrain Loss: 3.327\tDev score: 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.69it/s, avg_loss=5.47] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:2]\tTrain Loss: 0.483\tDev score: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.66it/s, avg_loss=4.13] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:3]\tTrain Loss: 0.365\tDev score: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.52it/s, avg_loss=1.36] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:4]\tTrain Loss: 0.120\tDev score: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.68it/s, avg_loss=1.28]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 5 with best score 0.923\n",
      "[E:5]\tTrain Loss: 0.113\tDev score: 0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.96it/s, avg_loss=1.12]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:6]\tTrain Loss: 0.099\tDev score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s, avg_loss=1.22]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:7]\tTrain Loss: 0.108\tDev score: 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s, avg_loss=1.17]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:8]\tTrain Loss: 0.103\tDev score: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.57it/s, avg_loss=1.14]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:9]\tTrain Loss: 0.100\tDev score: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.41it/s, avg_loss=1.11]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:10]\tTrain Loss: 0.098\tDev score: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s, avg_loss=1.1]   \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:11]\tTrain Loss: 0.097\tDev score: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.92it/s, avg_loss=1.1]   \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:12]\tTrain Loss: 0.097\tDev score: 0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s, avg_loss=1.09]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:13]\tTrain Loss: 0.096\tDev score: 0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.54it/s, avg_loss=1.09]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:14]\tTrain Loss: 0.096\tDev score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  2.04it/s, avg_loss=1.09]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:15]\tTrain Loss: 0.096\tDev score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.62it/s, avg_loss=1.08]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:16]\tTrain Loss: 0.096\tDev score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s, avg_loss=1.08]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:17]\tTrain Loss: 0.096\tDev score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.92it/s, avg_loss=1.08]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:18]\tTrain Loss: 0.096\tDev score: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.81it/s, avg_loss=1.08]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:19]\tTrain Loss: 0.096\tDev score: 0.909\n",
      "Restoring best model from iteration 5 with score 0.923\n",
      "Finished Training\n",
      "Accuracy: 0.923\n",
      "        y=1    y=2   \n",
      " l=1    52     18    \n",
      " l=2    17     366   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weight vector [0.5, 0.5]...\n",
      "\n",
      "Network architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[1] Testing {'l2': 0.0001, 'lr': 0.00019105920782773857}\n",
      "============================================================\n",
      "Using GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.78it/s, avg_loss=0.963] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.987\n",
      "[E:0]\tTrain Loss: 0.085\tDev score: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s, avg_loss=0.207] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:1]\tTrain Loss: 0.018\tDev score: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.78it/s, avg_loss=0.258] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 2 with best score 0.993\n",
      "[E:2]\tTrain Loss: 0.023\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.62it/s, avg_loss=0.122] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:3]\tTrain Loss: 0.011\tDev score: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.92it/s, avg_loss=0.0325] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:4]\tTrain Loss: 0.003\tDev score: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.55it/s, avg_loss=0.0119]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:5]\tTrain Loss: 0.001\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.61it/s, avg_loss=0.00897] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:6]\tTrain Loss: 0.001\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.62it/s, avg_loss=0.00737] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 7 with best score 1.000\n",
      "[E:7]\tTrain Loss: 0.001\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.76it/s, avg_loss=0.00637] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:8]\tTrain Loss: 0.001\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.71it/s, avg_loss=0.00589] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:9]\tTrain Loss: 0.001\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.71it/s, avg_loss=0.00556] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:10]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.51it/s, avg_loss=0.00538] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:11]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.55it/s, avg_loss=0.00523] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:12]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s, avg_loss=0.00509] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:13]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s, avg_loss=0.00497] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:14]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.57it/s, avg_loss=0.00485] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:15]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.67it/s, avg_loss=0.00473] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:16]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.72it/s, avg_loss=0.00461] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:17]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s, avg_loss=0.0045]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:18]\tTrain Loss: 0.000\tDev score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.83it/s, avg_loss=0.0044]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:19]\tTrain Loss: 0.000\tDev score: 1.000\n",
      "Restoring best model from iteration 7 with score 1.000\n",
      "Finished Training\n",
      "Accuracy: 1.000\n",
      "        y=1    y=2   \n",
      " l=1    69      0    \n",
      " l=2     0     384   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weight vector [0.5, 0.5]...\n",
      "\n",
      "Network architecture:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[2] Testing {'l2': 0.001, 'lr': 0.0019130784904478051}\n",
      "============================================================\n",
      "Using GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.90it/s, avg_loss=4.07] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.848\n",
      "[E:0]\tTrain Loss: 0.359\tDev score: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.65it/s, avg_loss=1.66] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:1]\tTrain Loss: 0.146\tDev score: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s, avg_loss=1.01]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:2]\tTrain Loss: 0.089\tDev score: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.56it/s, avg_loss=0.835] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:3]\tTrain Loss: 0.074\tDev score: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.63it/s, avg_loss=0.697] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 4 with best score 0.859\n",
      "[E:4]\tTrain Loss: 0.062\tDev score: 0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.65it/s, avg_loss=0.546] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 5 with best score 0.958\n",
      "[E:5]\tTrain Loss: 0.048\tDev score: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s, avg_loss=0.38]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 6 with best score 0.967\n",
      "[E:6]\tTrain Loss: 0.034\tDev score: 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.97it/s, avg_loss=0.278] \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 7 with best score 0.971\n",
      "[E:7]\tTrain Loss: 0.025\tDev score: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.87it/s, avg_loss=0.213]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:8]\tTrain Loss: 0.019\tDev score: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.71it/s, avg_loss=0.169]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 9 with best score 0.974\n",
      "[E:9]\tTrain Loss: 0.015\tDev score: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s, avg_loss=0.147]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 10 with best score 0.982\n",
      "[E:10]\tTrain Loss: 0.013\tDev score: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  2.12it/s, avg_loss=0.13]   \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:11]\tTrain Loss: 0.011\tDev score: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.93it/s, avg_loss=0.12]   \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 12 with best score 0.989\n",
      "[E:12]\tTrain Loss: 0.011\tDev score: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.67it/s, avg_loss=0.112]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 13 with best score 0.993\n",
      "[E:13]\tTrain Loss: 0.010\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.54it/s, avg_loss=0.108]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:14]\tTrain Loss: 0.010\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.67it/s, avg_loss=0.104]   \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:15]\tTrain Loss: 0.009\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.81it/s, avg_loss=0.102]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:16]\tTrain Loss: 0.009\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.42it/s, avg_loss=0.0998]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:17]\tTrain Loss: 0.009\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s, avg_loss=0.0987]  \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:18]\tTrain Loss: 0.009\tDev score: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s, avg_loss=0.0976]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:19]\tTrain Loss: 0.009\tDev score: 0.993\n",
      "Restoring best model from iteration 13 with score 0.993\n",
      "Finished Training\n",
      "Accuracy: 0.993\n",
      "        y=1    y=2   \n",
      " l=1    69      3    \n",
      " l=2     0     381   \n",
      "============================================================\n",
      "[SUMMARY]\n",
      "Best model: [1]\n",
      "Best config: {'l2': 0.0001, 'lr': 0.00019105920782773857}\n",
      "Best score: 1.0\n",
      "============================================================\n",
      "Accuracy: 0.904\n",
      "Precision: 0.588\n",
      "Recall: 0.919\n",
      "F1: 0.717\n",
      "Roc-auc: 0.950\n",
      "        y=1    y=2   \n",
      " l=1    147    103   \n",
      " l=2    13     945   \n"
     ]
    }
   ],
   "source": [
    "from metal.tuners import RandomSearchTuner\n",
    "# from metal.contrib.logging.tensorboard import TensorBoardWriter\n",
    "\n",
    "log_config = {\"log_dir\": \"./run_logs\", \"run_name\": \"image\"}\n",
    "\n",
    "tuner_config = {\"max_search\": 3}\n",
    "search_space = {\n",
    "    \"l2\": [0.001, 0.0001, 0.00001],  # linear range\n",
    "    \"lr\": {\"range\": [0.0001, 0.1], \"scale\": \"log\"},  # log range\n",
    "}\n",
    "\n",
    "\n",
    "train_config = em_config[\"train_config\"]\n",
    "\n",
    "\n",
    "# Defining network parameters\n",
    "num_classes = 2\n",
    "fc_size = 2\n",
    "hidden_size = 2\n",
    "pretrained = True\n",
    "\n",
    "# Set CUDA device\n",
    "torch.cuda.set_device(1)\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "# Initializing input module\n",
    "input_module = get_cnn(\"resnet18\", pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Initializing model object\n",
    "init_args = [[num_classes]]\n",
    "init_kwargs = {\"input_module\": input_module}\n",
    "init_kwargs.update(em_config)\n",
    "\n",
    "# init_kwargs.update(em_config)\n",
    "# max_search = tuner_config['max_search']\n",
    "# metric = train_config['validation_metric']\n",
    "\n",
    "# Training model as a single pass\n",
    "# if args.single_pass:\n",
    "# end_model = EndModel(\n",
    "#    [hidden_size, fc_size, num_classes],\n",
    "#    input_module=input_module,use_cuda='True'\n",
    "#     **em_config\n",
    "# )\n",
    "# end_model.train_model(\n",
    "#    train_data=train_loader,\n",
    "#    dev_data=dev_loader,\n",
    "#     **train_config\n",
    "# )\n",
    "\n",
    "# Searching model\n",
    "# else:\n",
    "searcher = RandomSearchTuner(EndModel, **log_config)\n",
    "\n",
    "end_model = searcher.search(\n",
    "    search_space,\n",
    "    dev_loader,\n",
    "    train_args=[train_loader],\n",
    "    init_args=init_args,\n",
    "    init_kwargs=init_kwargs,\n",
    "    train_kwargs=train_config,\n",
    "    max_search=tuner_config[\"max_search\"],\n",
    ")\n",
    "\n",
    "# Evaluating model\n",
    "scores = end_model.score(\n",
    "    test_loader, metric=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc-auc\"]\n",
    ")\n",
    "\n",
    "labels, _, probs = end_model._get_predictions(test_loader, return_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, _, probs = end_model._get_predictions(test_loader, return_probs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "============================================================\n",
    "[SUMMARY]\n",
    "Best model: [0]\n",
    "Best config: {'l2': 0.0001, 'lr': 0.0010025532524850966}\n",
    "Best score: 0.9955849889624724\n",
    "============================================================\n",
    "Accuracy: 0.926\n",
    "Precision: 0.675\n",
    "Recall: 0.856\n",
    "F1: 0.755\n",
    "Roc-auc: 0.964\n",
    "        y=1    y=2   \n",
    " l=1    137    66    \n",
    " l=2    23     982   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "\n",
    "for c, y in zip(test_cands[0], probs[:,0]):\n",
    "    doc_file_id = f\"{c[0].context.figure.document.name.lower()}.pdf::{os.path.basename(c[0].context.figure.url.lower())}\"\n",
    "    pred_dict[doc_file_id] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_fig_id = set()\n",
    "\n",
    "for doc in test_docs:\n",
    "    for fig in doc.figures:\n",
    "        doc_file_id = f\"{doc.name.lower()}.pdf::{os.path.basename(fig.url.lower())}\"\n",
    "        all_test_fig_id.add(doc_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0.7\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for id in all_test_fig_id:\n",
    "    if id in gt:\n",
    "        p = True\n",
    "    else: p = False\n",
    "    if id in pred_dict and pred_dict[id] >= b:\n",
    "        t = True\n",
    "    else: t = False\n",
    "    \n",
    "    if t and p: tp += 1\n",
    "    if t and not p: fp += 1\n",
    "    if not t and p: fn += 1\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "rec = tp / (tp + fn)\n",
    "f1 = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "tp, fp, fn, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
